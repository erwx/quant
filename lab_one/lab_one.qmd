---
title: "Lab #1 Walkthrough"
author: "Erik Whitfield"
date: "`r Sys.Date()`"
format:
  html:
    theme: solar
    toc: true
    self-contained: true
---

# The Task

We have a small data set.
We want to see what it contains and do some basic descriptive statistics.
This is pretty much how most quantitative analyses begin, so we want to get comfortable with the basics as soon as possible.

# The Data

The data we will use is a small `csv` file.
A `csv` file is a very common text file that stores data in rows and columns, with each value separated by a comma.
You'll encounter these files a lot in the wild.
The particular file that we are using here is called `labOne.csv`.
You can find it on Canvas under [Lab 1](https://canvas.colorado.edu/courses/122869/pages/lab-1?module_item_id=6724829).

# Getting Organized

You'll save yourself a lot of headaches by sticking to this workflow.

1. Make a course folder on your computer and call it `Quant`
2. Make a subfolder for each project or assignment that requires loading a data file (this one could be `lab_one`)
3. Save the relevant data file **inside this folder**
4. Use the RStudio menus to "Set Working Directory" to the same subfolder that contains the data file
5. Create a new script file inside this folder

You can check which directory you're in with the `getwd()` function.
If you type `getwd()` in the console, you'll see something like this (yours won't be exactly the same as mine):

```{R}
getwd()
```

In RStudio, you can look in the `Files` tab to see if the files you need are in the right place.
You can also use the `list.files()` function in the console.
I have some extra things in my directory because I'm making this document, but note that `labOne.R` and `labOne.csv` are here.

```{R}
list.files()
```

# Loading the Data

Now that everything is where it needs to be, we can start writing code in the `Source` pane in RStudio.
You will often hear people refer to this code as a *script*.
Think of it like a list of instructions that you want the computer to follow.
The `Source` pane is different from the `Console`.
The `Console` is for one-line, on-the-fly command execution.
It's very useful, but you can't save and share the code you type in the console.

The first thing we need to do is load the `csv` file so that we can analyze it.
R has a built-in function called `read.csv()` that lets us import the contents of a `csv` file.
I'm going to store the file contents in an object called `df`.
The name `d` is meaningless.
You can use any name you want.

```{R}
d <- read.csv("labOne.csv")
```

In R, `<-` is called the "assignment operator."
Technically, you *could* use an equal sign (`=`), but it's considered poor form because there are some rare instances in which this could cause errors.
`d` is a variable to which we are *assigning* the output of the `read.csv()` function.
`"labOne.csv"` is the *argument* that we are passing to `read.csv()`.
We can take a look at what `d` now contains by using the `head()` function.
By default, it will show you the first six rows of the data.
Note that `head()` doesn't alter the data in any way.
You could call the function over and over again, and the contents of `d` will remain unchanged.
Other operation *will* alter `d`.
I'll point them out as we go along.

```{R}
head(d)
```

# Interlude: Comments

When you're writing code, you'll find it very useful to leave notes for yourself and your collaborators along the way.
Something that makes perfect sense to you in the moment will look like an alien communication after you've been off the project for a few days.
Anything that follows a `#` character is a comment.
You can see it, but the computer will ignore it and it won't affect your results.

```{R}
#| error: true
# This is a comment.
## This is a comment, too.
#===========================================================#
# ~~~~~ You can write +ANYTHING+ you want after a `#` ~~~~~ #
#===========================================================#
# The computer will ignore this line because it starts with `#`
But this line will cause an error.
```


# Cleaning the Data

The data sets that you will encounter in this course will be very tidy.
Much of the data you will work with in real-world projects will be a hot mess.
Columns with cryptic names, non-standard characters, missing values, duplicate observations...it's rough out there.
The data set we have here is mostly fine, but I'm not a fan of the column names.
Personally, I like column names to be in all caps and I don't want any punctuation except for underscores (`_`).
In general, do what you prefer or what your collaborators want you to do.
(This isn't the most robust way to rename columns, but it's fine for now.)

Note that this is an instance in which we are altering the contents of `d`.

```{R}
colnames(d) <- c(
  "ID",
  "PROGRAM",
  "ANXIETY",
  "SD_RESPONSE",
  "AGE_MONTHS",
  "AGE_YEARS",
  "HEIGHT_INCH",
  "HEIGHT_FEET",
  "SHOE_SIZE",
  "COMMUTE",
  "TRANSPORTATION",
  "YEARS_OF_SCHOOL",
  "PET_YN",
  "PET_NUMBER",
  "PET_TYPE"
)

colnames(d)
```

# Descriptive Stats

Now, we can start doing some basic descriptive statistics.
We'll follow the questions that were in the Lab One Practice document on Canvas.

### What is the mean age in years for *everyone* in the data set?

As you may have guessed, R has a built-in function called `mean()`.
There are a few different ways to get the same result.
The first approach is the most common, but the others can be useful in certain scenarios.

```{R}
mean(d$AGE_YEARS)
mean(d[["AGE_YEARS"]])
mean(d[, "AGE_YEARS"])
```

Let's make a brief detour here to look at variables in R.
There are many times when we want to get the mean of a column and use it in other calculations.
To do this, we almost always want to store the value in a variable.
We use the assignment operator (`<-`) to do this:

```{R}
x <- mean(d$AGE_YEARS)
x
```

We can treat the variable `x` like a number:

```{R}
(45 - x) / nrow(d)
```

And we can pass the value contained in `x` around to other variables:

```{R}
y <- x
y
x + y
```

### What is the mean age for *students* in the data set?

Here, we are only interested in a subset of our data.
There are several ways to approach this.
One way is to make a *dummy* variable.
Dummy variables (sometimes called *indicator* variables) have a value of 1 or 0.
They are very useful, so it will be instructive to introduce them here.
For this question, we can make an `IS_STUDENT` dummy variable based on the `PROGRAM` variable.
This variable will be 1 for every observation where `PROGRAM` does *not* equal "Instructor".
It's not very exciting here because there is only one instructor, but I promise that you will use dummy variables a lot in your quantitative analyses.

```{R}
d$IS_STUDENT <- ifelse(d$PROGRAM != "Instructor", 1, 0)
# If PROGRAM isn't "Instructor", then put 1. Otherwise, put 0
```

Now, we can get the mean age for just the students a couple of different ways.
One way is to specify a subset of the data:

```{R}
student_mean_one <- mean(d$AGE_YEARS[d$IS_STUDENT == 1])
# Get the mean of the AGE_YEARS column for the rows where IS_STUDENT is 1, and store the result.
```

Another option is to make a new data frame that contains just the students:

```{R}
students <- d[d$IS_STUDENT == 1, ]
student_mean_two <- mean(students$AGE_YEARS)
```

If we did this right, the results should be the same:

```{R}
student_mean_one
student_mean_two
```

I prefer the second approach.
It's a little more typing, but it's much easier (in my opinion) to see what's happening.
When the data sets get larger and the computations get more complex, you may find that being verbose and clear is better than being concise and cryptic.

### Report the values requested below for the following variables (for everyone) in the data set. Round to two decimal places when it makes sense.

| | Age (years) | Height (feet) | Commute | Number of Pets | Stats Anxiety |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Mean** | | | | | |
| **Median** | | | | | |
| **Mode(s)** | | | | | |
| **(Population) Standard Deviation** | | | | | |
| **Min** | | | | | |
| **Max** | | | | | |

Some of you may have been introduced to some R libraries that automatically generate summary tables.
Those are great, and I encourage you to use them.
If you're interested in going a bit deeper with R, I suggest doing this sort of thing the hard way a few times.
Let's get the means first.

You've already seen how to use the `mean()` function.
I'll show you one of many (and I really mean many) ways to get the mean of multiple columns at once.
If you want to understand the way I do it below, then I encourage you to look up "for-loops" in R.
Every programming language has a way to do for-loops.
Don't worry if you don't understand this code.
It's mainly for demonstrative purposes.

```{R}
cols_to_keep <- c("AGE_YEARS", "HEIGHT_FEET", "COMMUTE", "PET_NUMBER", "ANXIETY")
for (column in cols_to_keep) {
  cat("The mean of", column, "is", round(mean(d[[column]]), 2), "\n")
}
```

We can use the same logic for the median:

```{R}
for (column in cols_to_keep) {
  cat("The median of", column, "is", round(median(d[[column]]), 2), "\n")
}
```

There is no built-in function for mode in R, so we have to roll our own:

```{R}
mode <- function(x) {
  uniqx <- unique(x)
  uniqx[which.max(tabulate(match(x, uniqx)))]
}

for (column in cols_to_keep) {
  cat("The mode of", column, "is", round(mode(d[[column]]), 2), "\n")
}
```

There is also no built-in function for population standard deviation in R.
The sample standard deviation is used much more often, but our book (and most books, I think) introduce population parameters before sample statistics.
Don't worry if the last sentence is meaningless right now.
You'll learn about the difference between parameters and statistics in the coming weeks.

```{R}
sd.p <- function(x) {
  sd(x)*sqrt((length(x)-1)/length(x))
}

for (column in cols_to_keep) {
  cat("The population sd of", column, "is", round(sd.p(d[[column]]), 2), "\n")
}
```

There are built-in functions for minimum and maximum.
They work as you might expect:

```{R}
for (column in cols_to_keep) {
  cat("The minimum of", column, "is", round(min(d[[column]]), 2), "and the maximum is", round(max(d[[column]]), 2), "\n")
}
```

We can check most of these values with the built-in `summary()` function:

```{R}
summary(d[cols_to_keep])
```

But, we wanted a table, so...


```{R}
summary_stats <- data.frame(
  Statistic = c("Mean", "Median", "Mode", "Population SD", "Min", "Max")
)

for (col in cols_to_keep) {
  summary_stats[[col]] <- c(
    round(mean(d[[col]]), 2),
    round(median(d[[col]]), 2),
    round(mode(d[[col]]), 2),
    round(sd.p(d[[col]]), 2),
    round(min(d[[col]]), 2),
    round(max(d[[col]]), 2)
  )
}

summary_stats
```

###  Write a brief paragraph about the descriptive statistics you reported in the table. This is a skill. It’s a balance between not going number by number (don’t describe every single number in the table) and telling the “story” of the data.

Full disclosure: I'm really bad at writing results.
I also find them incredibly tedious to read, but this is the life we chose.

> The mean age for people in EDUC 5716 was about 30 years old. The median is quite a bit lower at just under 27, suggesting that there may be some outliers pulling the mean up. The mean height for the class is about 5’6” and is quite similar to the median. The modal height for the class is 64. Commute distance among this class had a wide range of 54.5 miles, with a minimum commute of under 1 mile and a maximum of 55 miles. Like age, it seems likely that some outliers pulled the mean of around 15 miles several miles higher than the median of 11. In terms of pets, the most common response among this group was no pets, with a mean very near 1. The standard deviation of 1.78 seems quite large, reflecting the fact that some students in the course had many more pets, with the maximum reported value of 9! Finally, in terms of the stats anxiety scale, it is interesting that range reflects the lowest and highest possible values on the scale (1, 10); recall that these were the values when you filled the survey out yourselves! The mean and median were right around the middle point of the scale, 5, with the modal response being 7, suggesting that quite a few people entered the course with high levels of anxiety about statistics.  

### Which two variables are the most skewed? How do you know?

Age and commute are the most skewed.
The mean and the median are furthest apart.

### Use R to calculate the mean, median, and standard deviation for the following data set: 7, 8, 10, 6, 5

You can use the built-in functions to do this.
We can also use what we learn in class to do it from scratch.

```{R}
# The data set
x <- c(7, 8, 10, 6, 5)

# Calculate the mean
x_sum    <- sum(x)
n        <- length(x)
mean_val <- x_sum / n

# Calculate the median
sorted_x    <- sort(x)
median_val  <- sorted_x[(n + 1) / 2]

# Calculate the standard deviation (sample)
# First, calculate the squared differences from the mean
squared_differences <- (x - mean_val)^2

# Then, calculate the variance
variance <- sum(squared_differences) / (n - 1)

# Then, take the square root of the variance
sd_val <- sqrt(variance)

cat("Mean:", mean_val, "\n")
cat("Median:", median_val, "\n")
cat("Standard Deviation:", sd_val, "\n")
```

We can check if this is right:

```{R}
mean(x)
median(x)
sd(x)
```

### Use R to calculate the mean, median, and standard deviation for the following data set: 7, 8, 10, 6, 5, 100

```{R}
x <- c(7, 8, 10, 6, 5, 100)
mean(x)
median(x)
sd(x)
```

### How and why are the results different when we add an extreme value?

*I'll let you handle this one on your own.*
